# 1. Installation
Install `COLMAP` following the [official guideline](https://colmap.github.io/install.html).

Install `nerfstudio`.

```sh
# 1. Create environment
conda create --name nerfstudio -y python=3.8
conda activate nerfstudio
python -m pip install --upgrade pip

# 2. Install dependencies
pip install torch==2.1.2+cu118 torchvision==0.16.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118
pip install ninja git+https://github.com/NVlabs/tiny-cuda-nn/#subdirectory=bindings/torch

# 3. Install nerfstudio
pip install nerfstudio

# 4. Install SRecon-NeRF
cd nerfstudio-method-template/
pip install -e .
cd ..
```

# 2. Data processing
```sh
video_path=/path/to/your/video
image_path=data_in/my_dataset
dataset_path=dataset/my_dataset
python scripts/phrase_raw_data.py --video-path ${video_path} --output-folder-path ${image_path}
python scripts/colmap2nerf.py --images ${image_path}/images --run_colmap
python scripts/write_semantic_info_json.py --out_json_path ${image_path}/semantic_classes.json
```
For each images in the `{image_path}/images`, put the corresponding semantic label on the folder `{image_path}/segmentations`.      
Then, making sure the folder `data_in/my_dataset` includes the following necessary elements:
```sh
├── my_dataset
│   ├── images  # generated by phrase_raw_data.py
│   ├── semantic_classes.json # generated by write_semantic_info_json.py
│   ├── transforms_all.json  # generated by colmap2nerf.py
│   ├── segmentations  # need to be annotated
```
```sh
python scripts/gen_dataset.py --dataset_dir ${image_path}
```
The dataset is generated on the folder `dataset/my_dataset`




# 3. SRecon-NeRF training

```sh
conda activate nerfstudio
# training
ns-train my-semantic --data dataset/my_dataset --max_num_iterations 30000 --steps_per_save 5000 --save_only_latest_checkpoint False

# Visualize existing run
ns-viewer --load-config outputs/my_dataset/my-semantic/${your_logdir}/config.yml
```
The `${your_logdir}` can be founded on the terminal output.

# 4. Export point cloud
```sh
# backup, export_path is the installation path of the nerfstudio, here is the example of my path.
export_path='/home/ilab/anaconda3/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/exporter'
mv ${export_path}/exporter_utils.py ${export_path}/exporter_utils_backup.py
mv ${export_path}/texture_utils.py ${export_path}/texture_utils_backup.py

# replace file
export_path='/home/ilab/anaconda3/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/exporter'
cp nerf_studio_exporter/exporter_utils.py ${export_path}
cp nerf_studio_exporter/texture_utils.py ${export_path}

# export poind cloud
ns-export pointcloud --load-config outputs/my_dataset/my-semantic/${your_logdir}/config.yml --output-dir exports/mesh_semantic/ --normal-method open3d --num-points 1000000 --remove-outliers True --use-bounding-box True --bounding-box-min -2 -2 -1 --bounding-box-max 2 2 1

# recover
export_path='/home/ilab/anaconda3/envs/nerfstudio/lib/python3.8/site-packages/nerfstudio/exporter'
rm ${export_path}/exporter_utils.py
rm ${export_path}/texture_utils.py
mv ${export_path}/exporter_utils_backup.py ${export_path}/exporter_utils.py
mv ${export_path}/texture_utils_backup.py ${export_path}/texture_utils.py

```
